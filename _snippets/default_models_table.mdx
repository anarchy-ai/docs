|LLM-VM setting|Developer|LLM model|Model Size|
|-|-|-|-|
|```'chat_gpt'```|[OpenAI](https://platform.openai.com/)			 | [gpt-3.5-turbo-0301](https://platform.openai.com/docs/models/gpt-3-5)     |N/A|
|```'gpt'```     |[OpenAI](https://platform.openai.com/)			 | [text-davinci-003](https://platform.openai.com/docs/models/gpt-3)         |N/A|
|```'bloom'```   |[BigScience](https://huggingface.co/bigscience)         	 | [bloom-560](https://huggingface.co/bigscience/bloom-560m)                 |1.12 GB|
|```'flan'```    |[Google](https://huggingface.co/google)	                 | [flan-t5-small](https://huggingface.co/google/flan-t5-small)              |308 MB|
|```'llama'```   |[Openlm-Research](https://huggingface.co/openlm-research)	 | [open_llama_3b](https://huggingface.co/openlm-research/open_llama_3b)     |6.85 GB|
|```'neo'```     |[ElutherAI](https://huggingface.co/EleutherAI)      	 	 | [gpt-neo-1.3B](https://huggingface.co/EleutherAI/gpt-neo-1.3B)	     |5.31 GB|
|```'opt'```     |[Facebook](https://huggingface.co/facebook)       	 	 | [opt-350m](https://huggingface.co/facebook/opt-350m)                      |662 MB|
|```'pythia'```  |[ElutherAI](https://huggingface.co/EleutherAI)      	 	 | [pythia-70m-deduped](https://huggingface.co/EleutherAI/pythia-70m-deduped)|166 MB|
