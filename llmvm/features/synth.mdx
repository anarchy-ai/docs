---
title: Synthetic Distillation
description: 'The early version of Synthetic Distillation used a generator model trained adversarially against the student model to generate synthetic data to train the student model.'
---

## The Synthetic Distiller
**The artificial purifier**

There are three new ways to generate data synthetically:

1. Random sampling
Synthetic data are generated by sampling randomly from an input distribution. To obtain the best
results, the synthetic data should be drawn from a similar distribution as the actual data.
In the case where actual input data have been standardized, random samples can be drawn from a
Gaussian distribution ~ N (0, I). However in other cases, where the input has been scaled differently,
or has clearly defined input space boundaries, it is important to confirm the data distribution and
input space boundaries, and design the sampling method such that samples conform to the actual
input distribution as much as possible. The input distribution and input space bounds may be defined
using the available validation or test set or based upon some prior knowledge. 

2. Generator model
In this method, a generator model parameterized by a specific variable is trained to output samples
that would result in a large difference between the student and teacher model's predictions. This
generator model is trained in an adversarial manner against the student model during the distillation
process by optimizing the generator loss function. The student is trained using the student loss to minimize the difference between teacher and its own
predictions, the two opposing learning objectives are trained in a sequential adversarial manner, and
the student model is able to learn to match the predictions of the teacher model as training continues.

3. Direct optimization from random samples. To learn about the third method (which is more complicated), and to read everything in detail, check out the original source: https://arxiv.org/abs/2301.04338

### Running REBEL
**Getting started with REBEL is easy**
```python quickstart_REBEL.py
# import our client
from llm_vm.client import Client
import os

# Instantiate the client specifying which LLM you want to use
client = Client(big_model='chat_gpt', small_model='gpt') #REBEL will use chat_gpt no matter what big model is specified here, this specification exists for non-REBEL completion calls. 

#Calling client.complete with a tool list specified leads to the REBEL agent being used.
response = client.complete(
	 prompt = 'Is it warmer in Paris or Timbuktu and what are the temperatures in either city?',
         context='',
         openai_key=os.getenv("OPENAI_API_KEY"), #for REBEL we need an OpenAI key
         tools=[{'description': 'Find the weather at a location and returns it in celcius.',  #this tool list contains only one dictionary, therefore only one tool
                 'dynamic_params': {
		 		   "latitude": 'latitude of as a float',
		 		   "longitude": 'the longitude as a float'
				   },
                 'method': 'GET',
                 'url': "https://api.open-meteo.com/v1/forecast",
                 'static_params': {'current_weather': 'true'}}]) #No tools by default, so you have to add your own
print(response)
```
### Tool Definition
Tools are defined by dictionaries that are added to the list ```tools```. These dictionaries need to contain the following fields:

|Field| Type | Description|
|-|-|-|
|```'description'```| string | A description of what the tool does|
|```'dynamic_params'```| dictionary | A dictionary containing key value pairs (paramter name : description) of the API endpoint's mutable parameters that need to be set by REBEL in order to answer a query|
|```'method'```| string | ```GET``` or ```POST```, whichever is the type of the API endpoint|
|```'url'```| string | URL of the API endpoint that the given tool specifies|
|```'static_params'```| dictionary | Any parameters that are constant between all API calls. An API key/token is an example of this|

You can add any tool you want and as many as you need. REBEL will attempt to compositionally answer a question that may require calling multiple tools. 

<Snippet file="github.mdx" />
